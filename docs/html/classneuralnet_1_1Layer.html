<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>neuralnet: neuralnet::Layer Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">neuralnet
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>neuralnet</b></li><li class="navelem"><a class="el" href="classneuralnet_1_1Layer.html">Layer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="classneuralnet_1_1Layer-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">neuralnet::Layer Class Reference<span class="mlabels"><span class="mlabel">abstract</span></span></div>  </div>
</div><!--header-->
<div class="contents">

<p>Abstract base for unit of computation of a network.  
 <a href="classneuralnet_1_1Layer.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="layer_8hpp_source.html">layer.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for neuralnet::Layer:</div>
<div class="dyncontent">
<div class="center"><img src="classneuralnet_1_1Layer__inherit__graph.png" border="0" usemap="#neuralnet_1_1Layer_inherit__map" alt="Inheritance graph"/></div>
<!-- MAP 0 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for neuralnet::Layer:</div>
<div class="dyncontent">
<div class="center"><img src="classneuralnet_1_1Layer__coll__graph.png" border="0" usemap="#neuralnet_1_1Layer_coll__map" alt="Collaboration graph"/></div>
<!-- MAP 1 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ab3a383cd10179d05d30fa674a334dae3"><td class="memItemLeft" align="right" valign="top"><a id="ab3a383cd10179d05d30fa674a334dae3"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#ab3a383cd10179d05d30fa674a334dae3">GetNumInputs</a> ()</td></tr>
<tr class="memdesc:ab3a383cd10179d05d30fa674a334dae3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns number of inputs including bias. <br /></td></tr>
<tr class="separator:ab3a383cd10179d05d30fa674a334dae3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5fbd199b0983a81c21b366abfd59c6f1"><td class="memItemLeft" align="right" valign="top"><a id="a5fbd199b0983a81c21b366abfd59c6f1"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a5fbd199b0983a81c21b366abfd59c6f1">GetSize</a> ()</td></tr>
<tr class="memdesc:a5fbd199b0983a81c21b366abfd59c6f1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns number of neurons in this layer. <br /></td></tr>
<tr class="separator:a5fbd199b0983a81c21b366abfd59c6f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5485e918776cf9e7c58af494e69ff88f"><td class="memItemLeft" align="right" valign="top"><a id="a5485e918776cf9e7c58af494e69ff88f"></a>
std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a5485e918776cf9e7c58af494e69ff88f">GetLayerType</a> ()</td></tr>
<tr class="memdesc:a5485e918776cf9e7c58af494e69ff88f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns layer's class name. <br /></td></tr>
<tr class="separator:a5485e918776cf9e7c58af494e69ff88f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add27c4d2f2725b28a37ad9d9bbcc8f39"><td class="memItemLeft" align="right" valign="top"><a id="add27c4d2f2725b28a37ad9d9bbcc8f39"></a>
std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#add27c4d2f2725b28a37ad9d9bbcc8f39">GetOutputs</a> ()</td></tr>
<tr class="memdesc:add27c4d2f2725b28a37ad9d9bbcc8f39"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns vector of outputs from this layer's neurons. <br /></td></tr>
<tr class="separator:add27c4d2f2725b28a37ad9d9bbcc8f39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08abff765be63911088b4e888793507f"><td class="memItemLeft" align="right" valign="top"><a id="a08abff765be63911088b4e888793507f"></a>
std::vector&lt; double &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a08abff765be63911088b4e888793507f">GetWeights</a> ()</td></tr>
<tr class="memdesc:a08abff765be63911088b4e888793507f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns layer's weights matrix. <br /></td></tr>
<tr class="separator:a08abff765be63911088b4e888793507f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2da35925d900e217848443a07791b575"><td class="memItemLeft" align="right" valign="top"><a id="a2da35925d900e217848443a07791b575"></a>
virtual double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a2da35925d900e217848443a07791b575">GetLoss</a> (const std::vector&lt; double &gt; &amp;target_output)</td></tr>
<tr class="memdesc:a2da35925d900e217848443a07791b575"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return's layer's loss value. <br /></td></tr>
<tr class="separator:a2da35925d900e217848443a07791b575"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42aa0b61e8b5fae656af85a7b9d9a518"><td class="memItemLeft" align="right" valign="top"><a id="a42aa0b61e8b5fae656af85a7b9d9a518"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a42aa0b61e8b5fae656af85a7b9d9a518">SetGpuFlag</a> ()</td></tr>
<tr class="memdesc:a42aa0b61e8b5fae656af85a7b9d9a518"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets flag controlling whether gpu implementation is used. <br /></td></tr>
<tr class="separator:a42aa0b61e8b5fae656af85a7b9d9a518"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bfdef32fbedca487e3a6b432fc40b27"><td class="memItemLeft" align="right" valign="top"><a id="a4bfdef32fbedca487e3a6b432fc40b27"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a4bfdef32fbedca487e3a6b432fc40b27">ClearGpuFlag</a> ()</td></tr>
<tr class="memdesc:a4bfdef32fbedca487e3a6b432fc40b27"><td class="mdescLeft">&#160;</td><td class="mdescRight">Clears flag controlling whether gpu implementation is used. <br /></td></tr>
<tr class="separator:a4bfdef32fbedca487e3a6b432fc40b27"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a722c2673491edfb9c30c0f7b2fcca29a"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a722c2673491edfb9c30c0f7b2fcca29a">Initialize</a> (int num_inputs, int num_neurons)</td></tr>
<tr class="memdesc:a722c2673491edfb9c30c0f7b2fcca29a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initializes layer by reshaping its components and generating initial weights using layer specific default algorithm.  <a href="#a722c2673491edfb9c30c0f7b2fcca29a">More...</a><br /></td></tr>
<tr class="separator:a722c2673491edfb9c30c0f7b2fcca29a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a10b9155017dca618ca37ce3aa4546831"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a10b9155017dca618ca37ce3aa4546831">Initialize</a> (int num_inputs, int num_neurons, <a class="el" href="classneuralnet_1_1WeightsInitializationStrategy.html">WeightsInitializationStrategy</a> &amp;generator)</td></tr>
<tr class="memdesc:a10b9155017dca618ca37ce3aa4546831"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initializes layer by reshaping its components and generating initial weights using provided strategy.  <a href="#a10b9155017dca618ca37ce3aa4546831">More...</a><br /></td></tr>
<tr class="separator:a10b9155017dca618ca37ce3aa4546831"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0fb866c5377946f7099a820d69a0b2bd"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a0fb866c5377946f7099a820d69a0b2bd">ForwardProp</a> (const std::vector&lt; double &gt; &amp;input)</td></tr>
<tr class="memdesc:a0fb866c5377946f7099a820d69a0b2bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Activates this layer's neurons and returns output.  <a href="#a0fb866c5377946f7099a820d69a0b2bd">More...</a><br /></td></tr>
<tr class="separator:a0fb866c5377946f7099a820d69a0b2bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb2410cfc113d819c545132c5df33102"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#acb2410cfc113d819c545132c5df33102">BackProp</a> (const std::vector&lt; double &gt; &amp;weighted_error, const std::vector&lt; double &gt; &amp;prev_layer_output, double momentum)</td></tr>
<tr class="memdesc:acb2410cfc113d819c545132c5df33102"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes velocity of weights and returns weighted error of this layer.  <a href="#acb2410cfc113d819c545132c5df33102">More...</a><br /></td></tr>
<tr class="separator:acb2410cfc113d819c545132c5df33102"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98d81c554f666307c6387c9a86bb1bea"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a98d81c554f666307c6387c9a86bb1bea">Update</a> (double learning_rate)</td></tr>
<tr class="memdesc:a98d81c554f666307c6387c9a86bb1bea"><td class="mdescLeft">&#160;</td><td class="mdescRight">Updates weights matrix using velocity accumulated across training samples.  <a href="#a98d81c554f666307c6387c9a86bb1bea">More...</a><br /></td></tr>
<tr class="separator:a98d81c554f666307c6387c9a86bb1bea"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:a6482cc828fd4b3e913b382b0141817c4"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a6482cc828fd4b3e913b382b0141817c4">Reshape</a> (int num_inputs, int num_neurons)</td></tr>
<tr class="memdesc:a6482cc828fd4b3e913b382b0141817c4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Resizes and resets members of this class to accomodate required number of inputs and neurons.  <a href="#a6482cc828fd4b3e913b382b0141817c4">More...</a><br /></td></tr>
<tr class="separator:a6482cc828fd4b3e913b382b0141817c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32b8601861c0398fa4b4a8e20a80c9d2"><td class="memItemLeft" align="right" valign="top"><a id="a32b8601861c0398fa4b4a8e20a80c9d2"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a32b8601861c0398fa4b4a8e20a80c9d2">InitializeWeights</a> ()=0</td></tr>
<tr class="memdesc:a32b8601861c0398fa4b4a8e20a80c9d2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initializes weigths using default algorithm. <br /></td></tr>
<tr class="separator:a32b8601861c0398fa4b4a8e20a80c9d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ab5c885d08bbf2e818a164e3875fc73"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a5ab5c885d08bbf2e818a164e3875fc73">InitializeWeights</a> (<a class="el" href="classneuralnet_1_1WeightsInitializationStrategy.html">WeightsInitializationStrategy</a> &amp;generator)</td></tr>
<tr class="memdesc:a5ab5c885d08bbf2e818a164e3875fc73"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initializes weights using concrete <a class="el" href="classneuralnet_1_1WeightsInitializationStrategy.html" title="Weights initialization interface implementing strategy design pattern. ">WeightsInitializationStrategy</a>.  <a href="#a5ab5c885d08bbf2e818a164e3875fc73">More...</a><br /></td></tr>
<tr class="separator:a5ab5c885d08bbf2e818a164e3875fc73"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3aa08517de6a73640cd0e511c134b231"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a3aa08517de6a73640cd0e511c134b231">ForwardPropCpu</a> (const std::vector&lt; double &gt; &amp;input)=0</td></tr>
<tr class="memdesc:a3aa08517de6a73640cd0e511c134b231"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given input computes neurons' activations and applies activation function using cpu.  <a href="#a3aa08517de6a73640cd0e511c134b231">More...</a><br /></td></tr>
<tr class="separator:a3aa08517de6a73640cd0e511c134b231"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd0fdf1146eb28485349337e68ad7982"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#abd0fdf1146eb28485349337e68ad7982">ForwardPropGpu</a> (const std::vector&lt; double &gt; &amp;input)=0</td></tr>
<tr class="memdesc:abd0fdf1146eb28485349337e68ad7982"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given input computes neurons' activations and applies activation function using gpu.  <a href="#abd0fdf1146eb28485349337e68ad7982">More...</a><br /></td></tr>
<tr class="separator:abd0fdf1146eb28485349337e68ad7982"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb789462daab9227ff4ce6f7332bd38c"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#acb789462daab9227ff4ce6f7332bd38c">BackPropCpu</a> (const std::vector&lt; double &gt; &amp;weighted_error, const std::vector&lt; double &gt; &amp;prev_layer_output, double momentum)=0</td></tr>
<tr class="memdesc:acb789462daab9227ff4ce6f7332bd38c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes velocity of weights and weighted error of this layer using cpu.  <a href="#acb789462daab9227ff4ce6f7332bd38c">More...</a><br /></td></tr>
<tr class="separator:acb789462daab9227ff4ce6f7332bd38c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa81e9cfb0eaf5e17b38e011c4f56f042"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#aa81e9cfb0eaf5e17b38e011c4f56f042">BackPropGpu</a> (const std::vector&lt; double &gt; &amp;weighted_error, const std::vector&lt; double &gt; &amp;prev_layer_output, double momentum)=0</td></tr>
<tr class="memdesc:aa81e9cfb0eaf5e17b38e011c4f56f042"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes velocity of weights and weighted error of this layer using gpu.  <a href="#aa81e9cfb0eaf5e17b38e011c4f56f042">More...</a><br /></td></tr>
<tr class="separator:aa81e9cfb0eaf5e17b38e011c4f56f042"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24af23aba6bd257f90344d1c3d6d38b8"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a24af23aba6bd257f90344d1c3d6d38b8">UpdateCpu</a> (double learning_rate)</td></tr>
<tr class="memdesc:a24af23aba6bd257f90344d1c3d6d38b8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Updates weights with momentum accumulated across forward-backward passes using cpu.  <a href="#a24af23aba6bd257f90344d1c3d6d38b8">More...</a><br /></td></tr>
<tr class="separator:a24af23aba6bd257f90344d1c3d6d38b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af7520597d321aae360329b70f9476073"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#af7520597d321aae360329b70f9476073">UpdateGpu</a> (double learning_rate)</td></tr>
<tr class="memdesc:af7520597d321aae360329b70f9476073"><td class="mdescLeft">&#160;</td><td class="mdescRight">Updates weights with momentum accumulated across forward-backward passes using gpu.  <a href="#af7520597d321aae360329b70f9476073">More...</a><br /></td></tr>
<tr class="separator:af7520597d321aae360329b70f9476073"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e8f59ebde8c44d72004ba0d563b01c6"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a6e8f59ebde8c44d72004ba0d563b01c6">ComputeActivationCpu</a> (const std::vector&lt; double &gt; &amp;input)</td></tr>
<tr class="memdesc:a6e8f59ebde8c44d72004ba0d563b01c6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given inputs computes neurons' activations using cpu.  <a href="#a6e8f59ebde8c44d72004ba0d563b01c6">More...</a><br /></td></tr>
<tr class="separator:a6e8f59ebde8c44d72004ba0d563b01c6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a496fe8418591fde8ea2f151ae0e8f274"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a496fe8418591fde8ea2f151ae0e8f274">ComputeActivationGpu</a> (double *d_activation, const std::vector&lt; double &gt; &amp;input)</td></tr>
<tr class="memdesc:a496fe8418591fde8ea2f151ae0e8f274"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given inputs computes neurons' activations using gpu.  <a href="#a496fe8418591fde8ea2f151ae0e8f274">More...</a><br /></td></tr>
<tr class="separator:a496fe8418591fde8ea2f151ae0e8f274"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acfda6fbba248fc0bc9bebbc138e12092"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#acfda6fbba248fc0bc9bebbc138e12092">ComputeWeightedErrorCpu</a> ()</td></tr>
<tr class="memdesc:acfda6fbba248fc0bc9bebbc138e12092"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes vector required for calculating the error term in backpropagation step for hidden layers using cpu.  <a href="#acfda6fbba248fc0bc9bebbc138e12092">More...</a><br /></td></tr>
<tr class="separator:acfda6fbba248fc0bc9bebbc138e12092"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2990b68f97c1027baa9fdd718ed04591"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a2990b68f97c1027baa9fdd718ed04591">ComputeWeightedErrorGpu</a> (double *d_weighted_error, double *d_weights, double *d_error)</td></tr>
<tr class="memdesc:a2990b68f97c1027baa9fdd718ed04591"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes vector required for calculating the error term in backpropagation step for hidden layers using gpu.  <a href="#a2990b68f97c1027baa9fdd718ed04591">More...</a><br /></td></tr>
<tr class="separator:a2990b68f97c1027baa9fdd718ed04591"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a2716aec90e66d785acd202b297b4bb"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a7a2716aec90e66d785acd202b297b4bb">ComputeVelocityCpu</a> (const std::vector&lt; double &gt; &amp;prev_layer_output, double momentum)</td></tr>
<tr class="memdesc:a7a2716aec90e66d785acd202b297b4bb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes velocity of weights using cpu.  <a href="#a7a2716aec90e66d785acd202b297b4bb">More...</a><br /></td></tr>
<tr class="separator:a7a2716aec90e66d785acd202b297b4bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50fdc0a7f0702795eacf02b29c54f2b0"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a50fdc0a7f0702795eacf02b29c54f2b0">ComputeVelocityGpu</a> (double *d_velocity, const double *d_error, const double *d_prev_layer_output, double momentum)</td></tr>
<tr class="memdesc:a50fdc0a7f0702795eacf02b29c54f2b0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes velocity of weights using gpu.  <a href="#a50fdc0a7f0702795eacf02b29c54f2b0">More...</a><br /></td></tr>
<tr class="separator:a50fdc0a7f0702795eacf02b29c54f2b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a17192e2a166d6c93eab9e5cb1ae3ca8b"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a17192e2a166d6c93eab9e5cb1ae3ca8b">type_</a></td></tr>
<tr class="separator:a17192e2a166d6c93eab9e5cb1ae3ca8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee4be6e70fb225f18923065940330a26"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#aee4be6e70fb225f18923065940330a26">gpu_flag_</a> = false</td></tr>
<tr class="separator:aee4be6e70fb225f18923065940330a26"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68e1d25866b4dcc67cb2077d66903927"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a68e1d25866b4dcc67cb2077d66903927">num_neurons_</a> = 1</td></tr>
<tr class="separator:a68e1d25866b4dcc67cb2077d66903927"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a847df7ad431ecab992715e074f4ee727"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a847df7ad431ecab992715e074f4ee727">num_inputs_</a> = 2</td></tr>
<tr class="separator:a847df7ad431ecab992715e074f4ee727"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6d62e504bac81323fb080a06b2f99341"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a6d62e504bac81323fb080a06b2f99341">weights_</a></td></tr>
<tr class="separator:a6d62e504bac81323fb080a06b2f99341"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c4ae4520ce043abcb2d0b47720f37dc"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a4c4ae4520ce043abcb2d0b47720f37dc">velocity_</a></td></tr>
<tr class="separator:a4c4ae4520ce043abcb2d0b47720f37dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02c84d95e6a9e70e57b4f2b5d5e18ab9"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a02c84d95e6a9e70e57b4f2b5d5e18ab9">error_</a></td></tr>
<tr class="separator:a02c84d95e6a9e70e57b4f2b5d5e18ab9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a848eea2f5878b342484830b311fe0e08"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a848eea2f5878b342484830b311fe0e08">activation_</a></td></tr>
<tr class="separator:a848eea2f5878b342484830b311fe0e08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5cf4575860e583d5e6ff09841fa79ed"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#ac5cf4575860e583d5e6ff09841fa79ed">output_</a></td></tr>
<tr class="separator:ac5cf4575860e583d5e6ff09841fa79ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0baf6630ce4d07bd22815eedec391a72"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Layer.html#a0baf6630ce4d07bd22815eedec391a72">weighted_error_</a></td></tr>
<tr class="separator:a0baf6630ce4d07bd22815eedec391a72"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Abstract base for unit of computation of a network. </p>
<p><a class="el" href="classneuralnet_1_1Layer.html" title="Abstract base for unit of computation of a network. ">Layer</a> uses mini-batch backpropagation with momentum as a learning algorithm. Classes deriving from <a class="el" href="classneuralnet_1_1Layer.html" title="Abstract base for unit of computation of a network. ">Layer</a> have to implement ForwardPropCpu, ForwardPropGpu, BackPropCpu, BackPropGpu and InitializeWeights functions. Forward and Backward functions have to handle mini-batches of arbitrary size laid in matrix columns (stored in a vector using row major ordering). </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="acb2410cfc113d819c545132c5df33102"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acb2410cfc113d819c545132c5df33102">&#9670;&nbsp;</a></span>BackProp()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;double&gt; neuralnet::Layer::BackProp </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>weighted_error</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>prev_layer_output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>momentum</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes velocity of weights and returns weighted error of this layer. </p>
<p>For this function to work properly it has to be called after a single forward pass. This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering and returns a mini-batch of output. Note that if this layer is an output layer then target output should be passed as a weighted_error. In case this layer is first in network's topology, network's input should be passed as a prev_layer_output.</p>
<dl class="section pre"><dt>Precondition</dt><dd>There should be a ForwardProp preceding BackProp. </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">weighted_error</td><td>Weighted sum of succeeding layer's error for each neuron in this layer with coefficients being weights of connections with these neurons. </td></tr>
    <tr><td class="paramname">prev_layer_output</td><td>Return value of forward step in previous layer. </td></tr>
    <tr><td class="paramname">momentum</td><td>Momentum coefficient for velocity calculation. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Weighted sum of this layer's error for each input neuron excluding bias. </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If momentum value lies outside of (0, 1) set. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="acb789462daab9227ff4ce6f7332bd38c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acb789462daab9227ff4ce6f7332bd38c">&#9670;&nbsp;</a></span>BackPropCpu()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void neuralnet::Layer::BackPropCpu </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>weighted_error</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>prev_layer_output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>momentum</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes velocity of weights and weighted error of this layer using cpu. </p>
<p>This function should write to error_, velocity_ and weighted_error_. This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering and computes a mini-batch of output. Note that if this layer is an output layer then target output should be passed as a weighted_error. In case this layer is first in network's topology, network's input should be passed as a prev_layer_output.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">weighted_error</td><td>Weighted sum of succeeding layer's error for each neuron in this layer with coefficients being weights of connections with these neurons. </td></tr>
    <tr><td class="paramname">prev_layer_output</td><td>Return value of forward step in previous layer. </td></tr>
    <tr><td class="paramname">momentum</td><td>Momentum coefficient for velocity calculation. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If momentum value lies outside of (0, 1) set. </td></tr>
  </table>
  </dd>
</dl>

<p>Implemented in <a class="el" href="classneuralnet_1_1SoftmaxOutputLayer.html#a7360169d36832228b4938f9ff469bb59">neuralnet::SoftmaxOutputLayer</a>, <a class="el" href="classneuralnet_1_1SigmoidOutputLayer.html#a8020ad060ff1c3349bbf67ec3f3fccb8">neuralnet::SigmoidOutputLayer</a>, and <a class="el" href="classneuralnet_1_1ReLuLayer.html#a41da88c3eace20c2d8d2c397a9feb9d8">neuralnet::ReLuLayer</a>.</p>

</div>
</div>
<a id="aa81e9cfb0eaf5e17b38e011c4f56f042"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa81e9cfb0eaf5e17b38e011c4f56f042">&#9670;&nbsp;</a></span>BackPropGpu()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void neuralnet::Layer::BackPropGpu </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>weighted_error</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>prev_layer_output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>momentum</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes velocity of weights and weighted error of this layer using gpu. </p>
<p>This function should write to error_, velocity_ and weighted_error_. This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering and computes a mini-batch of output. Note that if this layer is an output layer then target output should be passed as a weighted_error. In case this layer is first in network's topology, network's input should be passed as a prev_layer_output.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">weighted_error</td><td>Weighted sum of succeeding layer's error for each neuron in this layer with coefficients being weights of connections with these neurons. </td></tr>
    <tr><td class="paramname">prev_layer_output</td><td>Return value of forward step in previous layer. </td></tr>
    <tr><td class="paramname">momentum</td><td>Momentum coefficient for velocity calculation. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If momentum value lies outside of (0, 1) set. </td></tr>
  </table>
  </dd>
</dl>

<p>Implemented in <a class="el" href="classneuralnet_1_1SoftmaxOutputLayer.html#af3308eebc5a7acc982f4ac0b55d34fc3">neuralnet::SoftmaxOutputLayer</a>, <a class="el" href="classneuralnet_1_1SigmoidOutputLayer.html#a0e9397124e10c8be7a7f587982e7c948">neuralnet::SigmoidOutputLayer</a>, and <a class="el" href="classneuralnet_1_1ReLuLayer.html#aafc499ba5e1de303b447ad1abb26f914">neuralnet::ReLuLayer</a>.</p>

</div>
</div>
<a id="a6e8f59ebde8c44d72004ba0d563b01c6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6e8f59ebde8c44d72004ba0d563b01c6">&#9670;&nbsp;</a></span>ComputeActivationCpu()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void neuralnet::Layer::ComputeActivationCpu </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Given inputs computes neurons' activations using cpu. </p>
<p>Activations vector is calculated by multiplying weights matrix by input matrix. Input matrix shouldn't contain bias inputs since this function adds it artificially during computation. This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering and computes a mini-batch of output.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td><a class="el" href="classneuralnet_1_1Layer.html" title="Abstract base for unit of computation of a network. ">Layer</a>'s input. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a496fe8418591fde8ea2f151ae0e8f274"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a496fe8418591fde8ea2f151ae0e8f274">&#9670;&nbsp;</a></span>ComputeActivationGpu()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void neuralnet::Layer::ComputeActivationGpu </td>
          <td>(</td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>d_activation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Given inputs computes neurons' activations using gpu. </p>
<p>Activations vector is calculated by multiplying weights matrix by input matrix. Input matrix shouldn't contain bias inputs since this function adds it artificially during computation. This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering and computes a mini-batch of output.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">d_activation</td><td>Pointer to memory location on gpu device containing array with activations. </td></tr>
    <tr><td class="paramname">input</td><td><a class="el" href="classneuralnet_1_1Layer.html" title="Abstract base for unit of computation of a network. ">Layer</a>'s input. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a7a2716aec90e66d785acd202b297b4bb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7a2716aec90e66d785acd202b297b4bb">&#9670;&nbsp;</a></span>ComputeVelocityCpu()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void neuralnet::Layer::ComputeVelocityCpu </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>prev_layer_output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>momentum</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes velocity of weights using cpu. </p>
<p>velocity(t) = momentum * velocity(t - 1) + (1.0 - momentum) * dE/dW,</p>
<p>where: t is a time step, dE/dW is a weights gradient calculated on the current mini-batch.</p>
<p>This function writes to velocity_ vector and assumes that error_ vector has been already calculated. This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering and computes a mini-batch of output.</p>
<dl class="section pre"><dt>Precondition</dt><dd>Error term for this layer is computed and stored in errors_. </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">prev_layer_output</td><td>Return value of forward step in previous layer. </td></tr>
    <tr><td class="paramname">momentum</td><td>Momentum coefficient for velocity calculation. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If momentum value lies outside of (0, 1) set. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a50fdc0a7f0702795eacf02b29c54f2b0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a50fdc0a7f0702795eacf02b29c54f2b0">&#9670;&nbsp;</a></span>ComputeVelocityGpu()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void neuralnet::Layer::ComputeVelocityGpu </td>
          <td>(</td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>d_velocity</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double *&#160;</td>
          <td class="paramname"><em>d_error</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double *&#160;</td>
          <td class="paramname"><em>d_prev_layer_output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>momentum</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes velocity of weights using gpu. </p>
<p>velocity(t) = momentum * velocity(t - 1) + (1.0 - momentum) * dE/dW,</p>
<p>where: t is a time step, dE/dW is a weights gradient calculated on the current mini-batch.</p>
<p>This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering and computes a mini-batch of output.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">d_velocity</td><td>Pointer to memory location on gpu device containing velocity matrix. </td></tr>
    <tr><td class="paramname">d_error</td><td>Pointer to memory location on gpu device containing error matrix. </td></tr>
    <tr><td class="paramname">d_prev_layer_output</td><td>Pointer to memory location on gpu device containing array storing preceding layer's output. </td></tr>
    <tr><td class="paramname">momentum</td><td>Momentum coefficient for velocity calculation. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If momentum value lies outside of (0, 1) set. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="acfda6fbba248fc0bc9bebbc138e12092"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acfda6fbba248fc0bc9bebbc138e12092">&#9670;&nbsp;</a></span>ComputeWeightedErrorCpu()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void neuralnet::Layer::ComputeWeightedErrorCpu </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes vector required for calculating the error term in backpropagation step for hidden layers using cpu. </p>
<p>This function writes to weighted_error_, Weighted error is calculated by multiplying transpose of weights matrix(without last row corresponding to bias input) by this layer's error vector. This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering and computes a mini-batch of output. </p>

</div>
</div>
<a id="a2990b68f97c1027baa9fdd718ed04591"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2990b68f97c1027baa9fdd718ed04591">&#9670;&nbsp;</a></span>ComputeWeightedErrorGpu()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void neuralnet::Layer::ComputeWeightedErrorGpu </td>
          <td>(</td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>d_weighted_error</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>d_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>d_error</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes vector required for calculating the error term in backpropagation step for hidden layers using gpu. </p>
<p>Weighted error is calculated by multiplying transpose of weights matrix (without last row corresponding to bias input) by this layer's error vector. This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering and computes a mini-batch of output.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">d_weighted_error</td><td>Pointer to memory location on gpu device containing weighted error array. </td></tr>
    <tr><td class="paramname">d_weights</td><td>Pointer to memory location on gpu device containing array storing weights matrix. </td></tr>
    <tr><td class="paramname">d_error</td><td>Pointer to memory location on gpu device containing error array. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a0fb866c5377946f7099a820d69a0b2bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0fb866c5377946f7099a820d69a0b2bd">&#9670;&nbsp;</a></span>ForwardProp()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;double&gt; neuralnet::Layer::ForwardProp </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Activates this layer's neurons and returns output. </p>
<p>This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering and returns mini-batch of output.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td><a class="el" href="classneuralnet_1_1Layer.html" title="Abstract base for unit of computation of a network. ">Layer</a>'s input. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Output from this layer's neurons. </dd></dl>

</div>
</div>
<a id="a3aa08517de6a73640cd0e511c134b231"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3aa08517de6a73640cd0e511c134b231">&#9670;&nbsp;</a></span>ForwardPropCpu()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void neuralnet::Layer::ForwardPropCpu </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Given input computes neurons' activations and applies activation function using cpu. </p>
<p>This function should write to output_. This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering and computes a mini-batch of output.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td><a class="el" href="classneuralnet_1_1Layer.html" title="Abstract base for unit of computation of a network. ">Layer</a>'s input. </td></tr>
  </table>
  </dd>
</dl>

<p>Implemented in <a class="el" href="classneuralnet_1_1SoftmaxOutputLayer.html#a6a18e1e7fc94cb7f3d66dfad2dcb1f85">neuralnet::SoftmaxOutputLayer</a>, <a class="el" href="classneuralnet_1_1SigmoidOutputLayer.html#a95e0f2dcabbb16bd24a59f19eaf0999f">neuralnet::SigmoidOutputLayer</a>, and <a class="el" href="classneuralnet_1_1ReLuLayer.html#a8828d7147d25d9854452e9d2e1e79857">neuralnet::ReLuLayer</a>.</p>

</div>
</div>
<a id="abd0fdf1146eb28485349337e68ad7982"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd0fdf1146eb28485349337e68ad7982">&#9670;&nbsp;</a></span>ForwardPropGpu()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void neuralnet::Layer::ForwardPropGpu </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Given input computes neurons' activations and applies activation function using gpu. </p>
<p>This function should write to output_. This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering and computes a mini-batch of output.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td><a class="el" href="classneuralnet_1_1Layer.html" title="Abstract base for unit of computation of a network. ">Layer</a>'s input. </td></tr>
  </table>
  </dd>
</dl>

<p>Implemented in <a class="el" href="classneuralnet_1_1SoftmaxOutputLayer.html#acb4f6f8739a3dedde111f11b548899f7">neuralnet::SoftmaxOutputLayer</a>, <a class="el" href="classneuralnet_1_1SigmoidOutputLayer.html#aaaa8a49435e351e688699a3d27db5c9a">neuralnet::SigmoidOutputLayer</a>, and <a class="el" href="classneuralnet_1_1ReLuLayer.html#a97dd16df35d4fb139e955d9a9acc2284">neuralnet::ReLuLayer</a>.</p>

</div>
</div>
<a id="a722c2673491edfb9c30c0f7b2fcca29a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a722c2673491edfb9c30c0f7b2fcca29a">&#9670;&nbsp;</a></span>Initialize() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void neuralnet::Layer::Initialize </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_neurons</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Initializes layer by reshaping its components and generating initial weights using layer specific default algorithm. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">num_inputs</td><td>Number of neurons in previous layer discounting bias. </td></tr>
    <tr><td class="paramname">num_neurons</td><td>Number of neurons in this layer discounting bias. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If num_inputs or num_neurons is not positive. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a10b9155017dca618ca37ce3aa4546831"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a10b9155017dca618ca37ce3aa4546831">&#9670;&nbsp;</a></span>Initialize() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void neuralnet::Layer::Initialize </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_neurons</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classneuralnet_1_1WeightsInitializationStrategy.html">WeightsInitializationStrategy</a> &amp;&#160;</td>
          <td class="paramname"><em>generator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Initializes layer by reshaping its components and generating initial weights using provided strategy. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">num_inputs</td><td>Number of neurons in previous layer discounting bias. </td></tr>
    <tr><td class="paramname">num_neurons</td><td>Number of neurons in this layer discounting bias. </td></tr>
    <tr><td class="paramname">generator</td><td>Concrete strategy for weights initialization. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If num_inputs or num_neurons is not positive. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a5ab5c885d08bbf2e818a164e3875fc73"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5ab5c885d08bbf2e818a164e3875fc73">&#9670;&nbsp;</a></span>InitializeWeights()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void neuralnet::Layer::InitializeWeights </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classneuralnet_1_1WeightsInitializationStrategy.html">WeightsInitializationStrategy</a> &amp;&#160;</td>
          <td class="paramname"><em>generator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Initializes weights using concrete <a class="el" href="classneuralnet_1_1WeightsInitializationStrategy.html" title="Weights initialization interface implementing strategy design pattern. ">WeightsInitializationStrategy</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">generator</td><td>Instance of concrete <a class="el" href="classneuralnet_1_1WeightsInitializationStrategy.html" title="Weights initialization interface implementing strategy design pattern. ">WeightsInitializationStrategy</a>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a6482cc828fd4b3e913b382b0141817c4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6482cc828fd4b3e913b382b0141817c4">&#9670;&nbsp;</a></span>Reshape()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void neuralnet::Layer::Reshape </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_neurons</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Resizes and resets members of this class to accomodate required number of inputs and neurons. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">num_inputs</td><td>Number of neurons in previous layer discounting bias. </td></tr>
    <tr><td class="paramname">num_neurons</td><td>Number of neurons in this layer discounting bias. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If num_inputs or num_neurons is not positive. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a98d81c554f666307c6387c9a86bb1bea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a98d81c554f666307c6387c9a86bb1bea">&#9670;&nbsp;</a></span>Update()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void neuralnet::Layer::Update </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>learning_rate</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Updates weights matrix using velocity accumulated across training samples. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">learning_rate</td><td>Speed with which this layer accepts new information. Pick this value carefully because if it's too big layer can diverge, and if it's too small it will take a long time to converge. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If learning_rate is not positive. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a24af23aba6bd257f90344d1c3d6d38b8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a24af23aba6bd257f90344d1c3d6d38b8">&#9670;&nbsp;</a></span>UpdateCpu()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void neuralnet::Layer::UpdateCpu </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>learning_rate</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Updates weights with momentum accumulated across forward-backward passes using cpu. </p>
<p>Weights are updated by substracting velocity multiplied by learning_rate from current weight.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">learning_rate</td><td>Speed with which this layer accepts new information. Pick this value carefully because if it's too big layer can diverge, and if it's too small it will take a long time to converge. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If learning_rate is not positive. </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented in <a class="el" href="classneuralnet_1_1SigmoidOutputLayer.html#acb41e05e0cbf78f2498b39ea4e4bedb0">neuralnet::SigmoidOutputLayer</a>.</p>

</div>
</div>
<a id="af7520597d321aae360329b70f9476073"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af7520597d321aae360329b70f9476073">&#9670;&nbsp;</a></span>UpdateGpu()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void neuralnet::Layer::UpdateGpu </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>learning_rate</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Updates weights with momentum accumulated across forward-backward passes using gpu. </p>
<p>Weights are updated by substracting velocity multiplied by learning_rate from current weight.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">learning_rate</td><td>Speed with which this layer accepts new information. Pick this value carefully because if it's too big layer can diverge, and if it's too small it will take a long time to converge. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If learning_rate is not positive. </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented in <a class="el" href="classneuralnet_1_1SigmoidOutputLayer.html#ae5760686dccc5dc3ebd99e5bf7e7a0b0">neuralnet::SigmoidOutputLayer</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a848eea2f5878b342484830b311fe0e08"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a848eea2f5878b342484830b311fe0e08">&#9670;&nbsp;</a></span>activation_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;double&gt; neuralnet::Layer::activation_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Activation of neurons in this layer i.e. linear combinations of inputs of a mini-batch (as one dimensional vectors) with coefficients being weigths of incoming connections with correspoding neurons from previous layer. Activations of each input in a mini-batch are laid in columns of a matrix stored as a vector using row major ordering. </p>

</div>
</div>
<a id="a02c84d95e6a9e70e57b4f2b5d5e18ab9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a02c84d95e6a9e70e57b4f2b5d5e18ab9">&#9670;&nbsp;</a></span>error_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;double&gt; neuralnet::Layer::error_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Error values for each neuron in this layer. </p>

</div>
</div>
<a id="aee4be6e70fb225f18923065940330a26"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee4be6e70fb225f18923065940330a26">&#9670;&nbsp;</a></span>gpu_flag_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool neuralnet::Layer::gpu_flag_ = false</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Flag controlling whether gpu implementation is used. </p>

</div>
</div>
<a id="a847df7ad431ecab992715e074f4ee727"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a847df7ad431ecab992715e074f4ee727">&#9670;&nbsp;</a></span>num_inputs_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int neuralnet::Layer::num_inputs_ = 2</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Number of inputs to each neuron in this layer taking into account bias. </p>

</div>
</div>
<a id="a68e1d25866b4dcc67cb2077d66903927"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a68e1d25866b4dcc67cb2077d66903927">&#9670;&nbsp;</a></span>num_neurons_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int neuralnet::Layer::num_neurons_ = 1</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Number of neurons in this layer discounting bias. </p>

</div>
</div>
<a id="ac5cf4575860e583d5e6ff09841fa79ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac5cf4575860e583d5e6ff09841fa79ed">&#9670;&nbsp;</a></span>output_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;double&gt; neuralnet::Layer::output_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Outputs of this layer's neurons i.e. outputs of activation function with activations as argument. Output to each input of mini-batch is laid in columns of a matrix stored as a vector using row major ordering. </p>

</div>
</div>
<a id="a17192e2a166d6c93eab9e5cb1ae3ca8b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a17192e2a166d6c93eab9e5cb1ae3ca8b">&#9670;&nbsp;</a></span>type_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string neuralnet::Layer::type_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>String storing layer's class name. </p>

</div>
</div>
<a id="a4c4ae4520ce043abcb2d0b47720f37dc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4c4ae4520ce043abcb2d0b47720f37dc">&#9670;&nbsp;</a></span>velocity_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;double&gt; neuralnet::Layer::velocity_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Linear representation of velocity matrix using row major ordering. </p>

</div>
</div>
<a id="a0baf6630ce4d07bd22815eedec391a72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0baf6630ce4d07bd22815eedec391a72">&#9670;&nbsp;</a></span>weighted_error_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;double&gt; neuralnet::Layer::weighted_error_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Mini-batch of weighted error i.e. for each neuron in previous layer it's a weighted sum of this layer's error with coefficients being weights of connections to that neuron. These values are laid in columns of a matrix stored as a vector using row major ordering. </p>

</div>
</div>
<a id="a6d62e504bac81323fb080a06b2f99341"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6d62e504bac81323fb080a06b2f99341">&#9670;&nbsp;</a></span>weights_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;double&gt; neuralnet::Layer::weights_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Linear representation of weights matrix using row major ordering. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>include/layers/<a class="el" href="layer_8hpp_source.html">layer.hpp</a></li>
<li>src/layers/layer.cpp</li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
