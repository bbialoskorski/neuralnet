<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>neuralnet: neuralnet::Net Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">neuralnet
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>neuralnet</b></li><li class="navelem"><a class="el" href="classneuralnet_1_1Net.html">Net</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="#friends">Friends</a> &#124;
<a href="classneuralnet_1_1Net-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">neuralnet::Net Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Abstraction of feedforward neural network.  
 <a href="classneuralnet_1_1Net.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="net_8hpp_source.html">net.hpp</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for neuralnet::Net:</div>
<div class="dyncontent">
<div class="center"><img src="classneuralnet_1_1Net__coll__graph.png" border="0" usemap="#neuralnet_1_1Net_coll__map" alt="Collaboration graph"/></div>
<!-- MAP 0 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ab42c28638b8bf8098a5fe08b3a656c3b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#ab42c28638b8bf8098a5fe08b3a656c3b">Net</a> (int input_layer_size, bool gpu_flag)</td></tr>
<tr class="memdesc:ab42c28638b8bf8098a5fe08b3a656c3b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs an empty network.  <a href="#ab42c28638b8bf8098a5fe08b3a656c3b">More...</a><br /></td></tr>
<tr class="separator:ab42c28638b8bf8098a5fe08b3a656c3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd6ca6af4811bbb6b2b4ee9de6429cea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#afd6ca6af4811bbb6b2b4ee9de6429cea">Net</a> (int input_layer_size, bool gpu_flag, std::shared_ptr&lt; <a class="el" href="classneuralnet_1_1NetIoHandler.html">NetIoHandler</a> &gt; io_handler)</td></tr>
<tr class="memdesc:afd6ca6af4811bbb6b2b4ee9de6429cea"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs an empty network.  <a href="#afd6ca6af4811bbb6b2b4ee9de6429cea">More...</a><br /></td></tr>
<tr class="separator:afd6ca6af4811bbb6b2b4ee9de6429cea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b2faa9eb2faffdaf01ed8b5318fe069"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#a0b2faa9eb2faffdaf01ed8b5318fe069">GetLoss</a> (const std::vector&lt; double &gt; &amp;target_output)</td></tr>
<tr class="memdesc:a0b2faa9eb2faffdaf01ed8b5318fe069"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given target output of most recent forward pass computes loss of output layer.  <a href="#a0b2faa9eb2faffdaf01ed8b5318fe069">More...</a><br /></td></tr>
<tr class="separator:a0b2faa9eb2faffdaf01ed8b5318fe069"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af43ecafb444803ac91367825096052d8"><td class="memItemLeft" align="right" valign="top"><a id="af43ecafb444803ac91367825096052d8"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#af43ecafb444803ac91367825096052d8">Save</a> (std::string file_path)</td></tr>
<tr class="memdesc:af43ecafb444803ac91367825096052d8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Exports network to a file. <br /></td></tr>
<tr class="separator:af43ecafb444803ac91367825096052d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b973c09cf9e8ec516d03f81eb14b415"><td class="memItemLeft" align="right" valign="top"><a id="a1b973c09cf9e8ec516d03f81eb14b415"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#a1b973c09cf9e8ec516d03f81eb14b415">Load</a> (std::string file_path)</td></tr>
<tr class="memdesc:a1b973c09cf9e8ec516d03f81eb14b415"><td class="mdescLeft">&#160;</td><td class="mdescRight">Imports network to a file. <br /></td></tr>
<tr class="separator:a1b973c09cf9e8ec516d03f81eb14b415"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3c10cfac5fdcec2875d124e22cc04a3"><td class="memItemLeft" align="right" valign="top"><a id="ad3c10cfac5fdcec2875d124e22cc04a3"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#ad3c10cfac5fdcec2875d124e22cc04a3">GetNumInputs</a> () const</td></tr>
<tr class="memdesc:ad3c10cfac5fdcec2875d124e22cc04a3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns number of inputs to a network. <br /></td></tr>
<tr class="separator:ad3c10cfac5fdcec2875d124e22cc04a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b75a3924917dc61febb4ec6d24cf770"><td class="memItemLeft" align="right" valign="top"><a id="a1b75a3924917dc61febb4ec6d24cf770"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#a1b75a3924917dc61febb4ec6d24cf770">GetNumLayers</a> () const</td></tr>
<tr class="memdesc:a1b75a3924917dc61febb4ec6d24cf770"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns number of layer's discounting input layer. <br /></td></tr>
<tr class="separator:a1b75a3924917dc61febb4ec6d24cf770"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae34f89c48ac47af9753360b5de77bdc7"><td class="memItemLeft" align="right" valign="top"><a id="ae34f89c48ac47af9753360b5de77bdc7"></a>
std::vector&lt; std::shared_ptr&lt; <a class="el" href="classneuralnet_1_1Layer.html">Layer</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#ae34f89c48ac47af9753360b5de77bdc7">GetLayers</a> ()</td></tr>
<tr class="memdesc:ae34f89c48ac47af9753360b5de77bdc7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns network's layers. <br /></td></tr>
<tr class="separator:ae34f89c48ac47af9753360b5de77bdc7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a71e15d9dbe5a60eb35fcceb7c5c93624"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#a71e15d9dbe5a60eb35fcceb7c5c93624">AddLayer</a> (std::shared_ptr&lt; <a class="el" href="classneuralnet_1_1Layer.html">Layer</a> &gt; layer, int num_neurons)</td></tr>
<tr class="memdesc:a71e15d9dbe5a60eb35fcceb7c5c93624"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adds layer to the end of the network and initializes its weights with layer specific default algorithm.  <a href="#a71e15d9dbe5a60eb35fcceb7c5c93624">More...</a><br /></td></tr>
<tr class="separator:a71e15d9dbe5a60eb35fcceb7c5c93624"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12e3eab09024035ce46c8034138d8a62"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#a12e3eab09024035ce46c8034138d8a62">AddLayer</a> (std::shared_ptr&lt; <a class="el" href="classneuralnet_1_1Layer.html">Layer</a> &gt; layer, int num_neurons, <a class="el" href="classneuralnet_1_1WeightsInitializationStrategy.html">WeightsInitializationStrategy</a> &amp;init_strategy)</td></tr>
<tr class="memdesc:a12e3eab09024035ce46c8034138d8a62"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adds layer to the end of the network and initializes its weights with provided strategy.  <a href="#a12e3eab09024035ce46c8034138d8a62">More...</a><br /></td></tr>
<tr class="separator:a12e3eab09024035ce46c8034138d8a62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0457c5c1ef86b843f4096a8ace3ad908"><td class="memItemLeft" align="right" valign="top"><a id="a0457c5c1ef86b843f4096a8ace3ad908"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#a0457c5c1ef86b843f4096a8ace3ad908">SetGpuFlag</a> ()</td></tr>
<tr class="memdesc:a0457c5c1ef86b843f4096a8ace3ad908"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets flag controlling whether gpu implementation is used. <br /></td></tr>
<tr class="separator:a0457c5c1ef86b843f4096a8ace3ad908"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3dcd162920af37bf02fcfaf9cb759f0d"><td class="memItemLeft" align="right" valign="top"><a id="a3dcd162920af37bf02fcfaf9cb759f0d"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#a3dcd162920af37bf02fcfaf9cb759f0d">ClearGpuFlag</a> ()</td></tr>
<tr class="memdesc:a3dcd162920af37bf02fcfaf9cb759f0d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Clears flag controlling whether gpu implementation is used. <br /></td></tr>
<tr class="separator:a3dcd162920af37bf02fcfaf9cb759f0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0129f8d6a5e624665cd3922fef79493d"><td class="memItemLeft" align="right" valign="top">virtual std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#a0129f8d6a5e624665cd3922fef79493d">ForwardProp</a> (const std::vector&lt; double &gt; &amp;input)</td></tr>
<tr class="memdesc:a0129f8d6a5e624665cd3922fef79493d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Propagates input forward through all layers.  <a href="#a0129f8d6a5e624665cd3922fef79493d">More...</a><br /></td></tr>
<tr class="separator:a0129f8d6a5e624665cd3922fef79493d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af6d95fdc4ccdc37d7150668fc74e8a36"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#af6d95fdc4ccdc37d7150668fc74e8a36">BackProp</a> (const std::vector&lt; double &gt; &amp;target_output, double momentum)</td></tr>
<tr class="memdesc:af6d95fdc4ccdc37d7150668fc74e8a36"><td class="mdescLeft">&#160;</td><td class="mdescRight">Propagates backward through layers using mini-batch momentum backpropagation algorithm.  <a href="#af6d95fdc4ccdc37d7150668fc74e8a36">More...</a><br /></td></tr>
<tr class="separator:af6d95fdc4ccdc37d7150668fc74e8a36"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a541fcd626459752b0de09a2a150f3d2a"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#a541fcd626459752b0de09a2a150f3d2a">Update</a> (double learning_rate)</td></tr>
<tr class="memdesc:a541fcd626459752b0de09a2a150f3d2a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Updates weights of every layer using velocity accumulated across forward-backward passes.  <a href="#a541fcd626459752b0de09a2a150f3d2a">More...</a><br /></td></tr>
<tr class="separator:a541fcd626459752b0de09a2a150f3d2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6fd85deb3c82bfe77ac7d6be2a539b9a"><td class="memItemLeft" align="right" valign="top"><a id="a6fd85deb3c82bfe77ac7d6be2a539b9a"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#a6fd85deb3c82bfe77ac7d6be2a539b9a">ResetVelocity</a> ()</td></tr>
<tr class="memdesc:a6fd85deb3c82bfe77ac7d6be2a539b9a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets velocity of every layer to zeros. <br /></td></tr>
<tr class="separator:a6fd85deb3c82bfe77ac7d6be2a539b9a"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:aa84c702ce8abcb7b034348d94f919838"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#aa84c702ce8abcb7b034348d94f919838">gpu_flag_</a> = false</td></tr>
<tr class="separator:aa84c702ce8abcb7b034348d94f919838"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae229ac240ce45c28d36d82bfb9bc1049"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#ae229ac240ce45c28d36d82bfb9bc1049">input_layer_size_</a></td></tr>
<tr class="separator:ae229ac240ce45c28d36d82bfb9bc1049"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4aa4d82f8323fccb58eccb06a52bf0bf"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classneuralnet_1_1Layer.html">Layer</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#a4aa4d82f8323fccb58eccb06a52bf0bf">layers_</a></td></tr>
<tr class="separator:a4aa4d82f8323fccb58eccb06a52bf0bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a477cc97557f82094b4787b7ebddaaf7f"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::vector&lt; double &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#a477cc97557f82094b4787b7ebddaaf7f">output_</a></td></tr>
<tr class="separator:a477cc97557f82094b4787b7ebddaaf7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a667dea73a52e84a82f7fff1da84cb9b7"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classneuralnet_1_1NetIoHandler.html">NetIoHandler</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classneuralnet_1_1Net.html#a667dea73a52e84a82f7fff1da84cb9b7">io_handler_</a></td></tr>
<tr class="separator:a667dea73a52e84a82f7fff1da84cb9b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="friends"></a>
Friends</h2></td></tr>
<tr class="memitem:a7af2d148b6d7436ce8f92759bf09dbf3"><td class="memItemLeft" align="right" valign="top"><a id="a7af2d148b6d7436ce8f92759bf09dbf3"></a>
class&#160;</td><td class="memItemRight" valign="bottom"><b>NetIoHandler</b></td></tr>
<tr class="separator:a7af2d148b6d7436ce8f92759bf09dbf3"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Abstraction of feedforward neural network. </p>
<p><a class="el" href="classneuralnet_1_1Net.html" title="Abstraction of feedforward neural network. ">Net</a> assembles layers together and abstracts out forward/backward propagation and updates to the level of a single entity. Network handles mini-batches of input laid in matrix columns and stored in a vector using row major ordering. Network created with default constructor uses <a class="el" href="classneuralnet_1_1NetJsonIoHandler.html" title="Handler for importing/exporting Net to/from json format. ">NetJsonIoHandler</a> for Save and Load. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ab42c28638b8bf8098a5fe08b3a656c3b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab42c28638b8bf8098a5fe08b3a656c3b">&#9670;&nbsp;</a></span>Net() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">neuralnet::Net::Net </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>input_layer_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>gpu_flag</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructs an empty network. </p>
<p>Network created with default constructor uses <a class="el" href="classneuralnet_1_1NetJsonIoHandler.html" title="Handler for importing/exporting Net to/from json format. ">NetJsonIoHandler</a> for Save and Load.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_layer_size</td><td>Size of input layer. </td></tr>
    <tr><td class="paramname">gpu_flag</td><td>Flag controlling whether gpu implementation is used in computation. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If input_layer_size is a positive number. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="afd6ca6af4811bbb6b2b4ee9de6429cea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afd6ca6af4811bbb6b2b4ee9de6429cea">&#9670;&nbsp;</a></span>Net() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">neuralnet::Net::Net </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>input_layer_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>gpu_flag</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classneuralnet_1_1NetIoHandler.html">NetIoHandler</a> &gt;&#160;</td>
          <td class="paramname"><em>io_handler</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructs an empty network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_layer_size</td><td>Size of input layer. </td></tr>
    <tr><td class="paramname">gpu_flag</td><td>Flag controlling whether gpu implementation is used in computation. </td></tr>
    <tr><td class="paramname">io_handler</td><td>Shared pointer to object of class derived from <a class="el" href="classneuralnet_1_1NetIoHandler.html" title="Abstract base class for network file import/export handler. ">NetIoHandler</a> which is used by <a class="el" href="classneuralnet_1_1Net.html#af43ecafb444803ac91367825096052d8" title="Exports network to a file. ">Save()</a> and <a class="el" href="classneuralnet_1_1Net.html#a1b973c09cf9e8ec516d03f81eb14b415" title="Imports network to a file. ">Load()</a> functions. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If input_layer_size is a positive number. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a71e15d9dbe5a60eb35fcceb7c5c93624"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a71e15d9dbe5a60eb35fcceb7c5c93624">&#9670;&nbsp;</a></span>AddLayer() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void neuralnet::Net::AddLayer </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classneuralnet_1_1Layer.html">Layer</a> &gt;&#160;</td>
          <td class="paramname"><em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_neurons</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Adds layer to the end of the network and initializes its weights with layer specific default algorithm. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">layer</td><td>Shared pointer to the layer you want to add.  Desired size of the layer discounting bias neuron. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If num_neurons is not positive. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a12e3eab09024035ce46c8034138d8a62"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a12e3eab09024035ce46c8034138d8a62">&#9670;&nbsp;</a></span>AddLayer() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void neuralnet::Net::AddLayer </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classneuralnet_1_1Layer.html">Layer</a> &gt;&#160;</td>
          <td class="paramname"><em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_neurons</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classneuralnet_1_1WeightsInitializationStrategy.html">WeightsInitializationStrategy</a> &amp;&#160;</td>
          <td class="paramname"><em>init_strategy</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Adds layer to the end of the network and initializes its weights with provided strategy. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">layer</td><td>Shared pointer to the layer you want to add. </td></tr>
    <tr><td class="paramname">num_neurons</td><td>Desired size of the layer discounting bias neuron. </td></tr>
    <tr><td class="paramname">init_strategy</td><td>Concrete strategy for weights initialization. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If num_neurons is not positive. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="af6d95fdc4ccdc37d7150668fc74e8a36"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af6d95fdc4ccdc37d7150668fc74e8a36">&#9670;&nbsp;</a></span>BackProp()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void neuralnet::Net::BackProp </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>target_output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>momentum</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Propagates backward through layers using mini-batch momentum backpropagation algorithm. </p>
<p>For this function to work properly it has to be called after a single forward pass. This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering.</p>
<dl class="section pre"><dt>Precondition</dt><dd>There should be a ForwardProp preceding BackProp. </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">target_output</td><td>Output expected from the last ForwardProp call. </td></tr>
    <tr><td class="paramname">momentum</td><td>Momentum coefficient for velocity calculation. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If momentum value lies outside of (0,1) set. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a0129f8d6a5e624665cd3922fef79493d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0129f8d6a5e624665cd3922fef79493d">&#9670;&nbsp;</a></span>ForwardProp()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; double &gt; neuralnet::Net::ForwardProp </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Propagates input forward through all layers. </p>
<p>Network's input is fed to the first layer and each layer's output is fed to the next layer. This functions accepts mini-batch laid in matrix columns stored in a vector using row major ordering and returns mini-batch of output.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Network's input. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Output of last layer in the network. </dd></dl>

</div>
</div>
<a id="a0b2faa9eb2faffdaf01ed8b5318fe069"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b2faa9eb2faffdaf01ed8b5318fe069">&#9670;&nbsp;</a></span>GetLoss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double neuralnet::Net::GetLoss </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>target_output</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Given target output of most recent forward pass computes loss of output layer. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">target_output</td><td>Correct output to most recent minibatch of input. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a541fcd626459752b0de09a2a150f3d2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a541fcd626459752b0de09a2a150f3d2a">&#9670;&nbsp;</a></span>Update()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void neuralnet::Net::Update </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>learning_rate</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Updates weights of every layer using velocity accumulated across forward-backward passes. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">learning_rate</td><td>Speed with which this network accepts new information. Pick this value carefully because if it's too big network can diverge, and if it's too small it will take a long time time to converge. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if learning_rate is not positive. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="aa84c702ce8abcb7b034348d94f919838"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa84c702ce8abcb7b034348d94f919838">&#9670;&nbsp;</a></span>gpu_flag_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool neuralnet::Net::gpu_flag_ = false</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Flag controlling whether gpu implementation is used. </p>

</div>
</div>
<a id="ae229ac240ce45c28d36d82bfb9bc1049"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae229ac240ce45c28d36d82bfb9bc1049">&#9670;&nbsp;</a></span>input_layer_size_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int neuralnet::Net::input_layer_size_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Number of double values that network accepts as a single input in forward pass. Mini-batches need to have a size being a multiple of this number. </p>

</div>
</div>
<a id="a667dea73a52e84a82f7fff1da84cb9b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a667dea73a52e84a82f7fff1da84cb9b7">&#9670;&nbsp;</a></span>io_handler_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt;<a class="el" href="classneuralnet_1_1NetIoHandler.html">NetIoHandler</a>&gt; neuralnet::Net::io_handler_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Object handling import/export of the network to/from file. </p>

</div>
</div>
<a id="a4aa4d82f8323fccb58eccb06a52bf0bf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4aa4d82f8323fccb58eccb06a52bf0bf">&#9670;&nbsp;</a></span>layers_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::shared_ptr&lt;<a class="el" href="classneuralnet_1_1Layer.html">Layer</a>&gt; &gt; neuralnet::Net::layers_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Layers composing neural network. </p>

</div>
</div>
<a id="a477cc97557f82094b4787b7ebddaaf7f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a477cc97557f82094b4787b7ebddaaf7f">&#9670;&nbsp;</a></span>output_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::vector&lt;double&gt; &gt; neuralnet::Net::output_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Output of the network. Output to each input of mini-batch is laid in columns of a matrix stored as a vector using row major ordering. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>include/<a class="el" href="net_8hpp_source.html">net.hpp</a></li>
<li>src/net.cpp</li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
