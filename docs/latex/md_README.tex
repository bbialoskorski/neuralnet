{\bfseries neuralnet} is my c++ implementation of a simple feedfoward neural network developed for educational purposes. For learning process of the network this project uses a variant of backpropagation algorithm called a mini-\/batch gradient descent with momentum. I\textquotesingle{}ve created two implementations for forward, backward propagation and updates\+: on G\+PU using C\+U\+DA and on C\+PU using Open\+MP.

\subsubsection*{Goals for this project\+:}


\begin{DoxyItemize}
\item Learn about feedforward neural networks.
\item Learn about scientific parallel computing on cpu using Open\+MP api.
\item Learn about parallel computing on gpu using N\+V\+I\+D\+IA C\+U\+DA toolkit.
\item Successfully implement and train the network on real life use case dataset (M\+N\+I\+ST handwritten digits dataset).
\item When developing parallel code focus on performance.
\item Deepen c++ knowledge in a process. \subsubsection*{Available layer types\+:}
\end{DoxyItemize}


\begin{DoxyItemize}
\item Rectified Linear Unit Layer
\item Softmax Outut Layer
\item Sigmoid Output Layer \subsubsection*{Example\+:}
\end{DoxyItemize}

{\itshape Code example goes here} Results\+: 